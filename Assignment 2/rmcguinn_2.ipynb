{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u63QTLuU_aDl"
      },
      "source": [
        "## Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g22kB-cI_aDl",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "bc584b2c-b50e-4aeb-9cc0-5260b8797042"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a59b792-9f28-4b6d-828c-1832f1b61d1b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a59b792-9f28-4b6d-828c-1832f1b61d1b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"rmcguinn\",\"key\":\"a2bf522b0978ccc21f7ec3bd7c8fd022\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4TEO4xl_aDn"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW4dLLRj_aDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64075a50-0845-4cf9-bbb5-0da7393befa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 802M/812M [00:04<00:00, 236MB/s]\n",
            "100% 812M/812M [00:04<00:00, 208MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQSk6DFz_aDo"
      },
      "outputs": [],
      "source": [
        "!unzip -qq dogs-vs-cats.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq train.zip"
      ],
      "metadata": {
        "id": "bigvJznzKrqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfV2aTlv_aDo"
      },
      "source": [
        "**Copying images to training, validation, and test directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mywltRPQ_aDp"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name: str, start_index: int, end_index: int) -> None:\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "            \n",
        "\n",
        "make_subset(\"test\", start_index=0, end_index=500)\n",
        "make_subset(\"validation\", start_index=500, end_index=1000)\n",
        "make_subset(\"train\", start_index=1000, end_index=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ebEnC0_aDr"
      },
      "source": [
        "**Using `image_dataset_from_directory` to read images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64YZvJI1_aDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf1787c-60ad-4bb6-d6f9-7e66ffe33cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNa12iI3_aDj"
      },
      "source": [
        "# Training a convnet from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a small sample size"
      ],
      "metadata": {
        "id": "ufRsEz9CfNkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we use a training sample size with just 1000 samples. The validation and test set size will be 500 samples each."
      ],
      "metadata": {
        "id": "I367VzoNTOM4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zGj62xf_aDp"
      },
      "source": [
        "### Using an unregularized model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should not expect an unregularizedd model with a small training sample to perform well, but we should at least include this to see how well regularizing the model improves the performance. The test loss on this model is 0.5283."
      ],
      "metadata": {
        "id": "czcCikcETuWc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPbTTXiU_aDq"
      },
      "source": [
        "**Instantiating a small convnet for dogs vs. cats classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW1YfZuJ_aDq"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYD0NzzZ_aDu"
      },
      "source": [
        "**Fitting the model using a `Dataset`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VSzMVkn_aDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1eb260-fe26-4c61-bcfd-9735ebc5d6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 20s 123ms/step - loss: 0.7004 - accuracy: 0.5285 - val_loss: 0.6912 - val_accuracy: 0.5750\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.6944 - accuracy: 0.5870 - val_loss: 0.6706 - val_accuracy: 0.5920\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.6703 - accuracy: 0.6155 - val_loss: 0.6377 - val_accuracy: 0.6320\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 7s 113ms/step - loss: 0.6361 - accuracy: 0.6480 - val_loss: 0.7505 - val_accuracy: 0.6080\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.6036 - accuracy: 0.6800 - val_loss: 0.7940 - val_accuracy: 0.6180\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.5712 - accuracy: 0.7105 - val_loss: 0.5894 - val_accuracy: 0.6910\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.5328 - accuracy: 0.7325 - val_loss: 0.6315 - val_accuracy: 0.6570\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 7s 114ms/step - loss: 0.5013 - accuracy: 0.7570 - val_loss: 0.5567 - val_accuracy: 0.7210\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.4616 - accuracy: 0.7785 - val_loss: 0.5684 - val_accuracy: 0.7270\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.3934 - accuracy: 0.8285 - val_loss: 0.6439 - val_accuracy: 0.7210\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.3542 - accuracy: 0.8560 - val_loss: 0.7178 - val_accuracy: 0.7190\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.2778 - accuracy: 0.8855 - val_loss: 0.6677 - val_accuracy: 0.7100\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.2358 - accuracy: 0.9030 - val_loss: 0.7107 - val_accuracy: 0.7530\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.2021 - accuracy: 0.9305 - val_loss: 0.9566 - val_accuracy: 0.7280\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.1500 - accuracy: 0.9480 - val_loss: 0.9922 - val_accuracy: 0.7180\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 7s 114ms/step - loss: 0.1239 - accuracy: 0.9520 - val_loss: 0.9204 - val_accuracy: 0.7400\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.1048 - accuracy: 0.9630 - val_loss: 1.0481 - val_accuracy: 0.7210\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.0745 - accuracy: 0.9740 - val_loss: 1.0677 - val_accuracy: 0.7460\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.1047 - accuracy: 0.9675 - val_loss: 0.9978 - val_accuracy: 0.7480\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.0575 - accuracy: 0.9845 - val_loss: 1.4247 - val_accuracy: 0.7480\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.0578 - accuracy: 0.9825 - val_loss: 1.6234 - val_accuracy: 0.6980\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 1.4419 - val_accuracy: 0.7560\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0611 - accuracy: 0.9800 - val_loss: 1.6420 - val_accuracy: 0.7330\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 1.2888 - val_accuracy: 0.7550\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 1.6807 - val_accuracy: 0.7320\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 1.8924 - val_accuracy: 0.7140\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 2.0666 - val_accuracy: 0.7020\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.0831 - accuracy: 0.9795 - val_loss: 2.0581 - val_accuracy: 0.7340\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 7s 113ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 2.0813 - val_accuracy: 0.7230\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 7s 113ms/step - loss: 0.0466 - accuracy: 0.9870 - val_loss: 2.3231 - val_accuracy: 0.6940\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "job3nvbL_aDw"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ3f8vbC_aDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec30a97-0b28-4b91-c7ac-8f897ed72d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 46ms/step - loss: 0.5283 - accuracy: 0.7460\n",
            "Test accuracy: 0.746\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using dropout"
      ],
      "metadata": {
        "id": "q0C_3K7vkurq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, using dropout on the last dense layer at 50% makes the model perform worse than the unregularized model. To avoid unnessessary bloat on this project, 50% is the only dropout rate tested here, and instead test other regularization methods."
      ],
      "metadata": {
        "id": "5IpCDu9QVKw1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TGVW9CllHqQ"
      },
      "source": [
        "**Defining a new convnet that includes dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sACMRiO7lAoj"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i36ilgDtlAo4"
      },
      "source": [
        "**Training the regularized convnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ECzMFyelAo5",
        "outputId": "5dcfd436-83a6-4be9-d890-6ad487144545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 9s 114ms/step - loss: 0.7285 - accuracy: 0.5230 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.6995 - accuracy: 0.5250 - val_loss: 0.6864 - val_accuracy: 0.5310\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.6913 - accuracy: 0.5395 - val_loss: 1.0863 - val_accuracy: 0.4990\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.6767 - accuracy: 0.5925 - val_loss: 0.6685 - val_accuracy: 0.6040\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.6530 - accuracy: 0.6275 - val_loss: 0.6521 - val_accuracy: 0.6450\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.6395 - accuracy: 0.6460 - val_loss: 0.6269 - val_accuracy: 0.6680\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.5889 - accuracy: 0.6900 - val_loss: 0.6520 - val_accuracy: 0.6670\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.5789 - accuracy: 0.7055 - val_loss: 0.6646 - val_accuracy: 0.6310\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.5429 - accuracy: 0.7270 - val_loss: 0.6258 - val_accuracy: 0.6990\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.5174 - accuracy: 0.7410 - val_loss: 0.6118 - val_accuracy: 0.6690\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.4602 - accuracy: 0.7910 - val_loss: 0.5717 - val_accuracy: 0.7320\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.4212 - accuracy: 0.8060 - val_loss: 0.6358 - val_accuracy: 0.7020\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.3798 - accuracy: 0.8290 - val_loss: 0.6187 - val_accuracy: 0.7320\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.3458 - accuracy: 0.8495 - val_loss: 0.7946 - val_accuracy: 0.6830\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.2969 - accuracy: 0.8720 - val_loss: 0.6809 - val_accuracy: 0.7290\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.2648 - accuracy: 0.8885 - val_loss: 0.9066 - val_accuracy: 0.7250\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.2369 - accuracy: 0.9030 - val_loss: 0.8441 - val_accuracy: 0.7040\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.1869 - accuracy: 0.9220 - val_loss: 0.9917 - val_accuracy: 0.7030\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.1637 - accuracy: 0.9295 - val_loss: 0.7767 - val_accuracy: 0.7500\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.1376 - accuracy: 0.9475 - val_loss: 1.0208 - val_accuracy: 0.7320\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.1289 - accuracy: 0.9460 - val_loss: 1.1981 - val_accuracy: 0.7120\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.1133 - accuracy: 0.9570 - val_loss: 1.0677 - val_accuracy: 0.7490\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.0969 - accuracy: 0.9660 - val_loss: 1.1057 - val_accuracy: 0.7530\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 7s 112ms/step - loss: 0.0967 - accuracy: 0.9680 - val_loss: 1.2835 - val_accuracy: 0.7360\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 1.7096 - val_accuracy: 0.7090\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.1013 - accuracy: 0.9670 - val_loss: 1.3157 - val_accuracy: 0.7310\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.0660 - accuracy: 0.9745 - val_loss: 1.3245 - val_accuracy: 0.7510\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.0666 - accuracy: 0.9725 - val_loss: 1.3026 - val_accuracy: 0.7520\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 1.3615 - val_accuracy: 0.7490\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0726 - accuracy: 0.9740 - val_loss: 1.5533 - val_accuracy: 0.7320\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jka6jOmplAo6"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChofeNMZlAo7",
        "outputId": "87de2746-91ec-4d20-81b3-7b85d39b9aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 48ms/step - loss: 0.5478 - accuracy: 0.7420\n",
            "Test accuracy: 0.742\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF90OEvQ_aDw"
      },
      "source": [
        "### Using image augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation is a more suitable regularization technique for image classification, and it shows with test loss reduced to 0.4591 and much better accuracy than the unregularized model."
      ],
      "metadata": {
        "id": "Bpl0Lm18WI_J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6I9f2jR_aDw"
      },
      "source": [
        "**Define a data augmentation stage to add to an image model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svPGFOwq_aDx"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKEtAP4Q_aDy"
      },
      "source": [
        "**Defining a new convnet that includes image augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZRAgJBL_aDy"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiJk6EKg_aDy"
      },
      "source": [
        "**Training the regularized convnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn8M3BRb_aDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dd930c-1677-4473-ec59-671503c3d140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "63/63 [==============================] - 10s 121ms/step - loss: 0.8457 - accuracy: 0.5135 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 2/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.7047 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5130\n",
            "Epoch 3/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.7005 - accuracy: 0.5665 - val_loss: 0.6859 - val_accuracy: 0.5470\n",
            "Epoch 4/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6888 - accuracy: 0.5855 - val_loss: 0.6529 - val_accuracy: 0.6040\n",
            "Epoch 5/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6614 - accuracy: 0.6175 - val_loss: 0.6688 - val_accuracy: 0.6150\n",
            "Epoch 6/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.6693 - accuracy: 0.6020 - val_loss: 0.6320 - val_accuracy: 0.6630\n",
            "Epoch 7/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.6279 - accuracy: 0.6595 - val_loss: 0.7701 - val_accuracy: 0.6050\n",
            "Epoch 8/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.6350 - accuracy: 0.6560 - val_loss: 0.5993 - val_accuracy: 0.6860\n",
            "Epoch 9/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6204 - accuracy: 0.6570 - val_loss: 0.5924 - val_accuracy: 0.7060\n",
            "Epoch 10/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6048 - accuracy: 0.6860 - val_loss: 0.6704 - val_accuracy: 0.6550\n",
            "Epoch 11/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5835 - accuracy: 0.6875 - val_loss: 0.6703 - val_accuracy: 0.6330\n",
            "Epoch 12/60\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.5747 - accuracy: 0.7110 - val_loss: 0.6574 - val_accuracy: 0.7020\n",
            "Epoch 13/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5581 - accuracy: 0.7155 - val_loss: 0.7295 - val_accuracy: 0.6370\n",
            "Epoch 14/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5573 - accuracy: 0.7175 - val_loss: 0.5809 - val_accuracy: 0.6940\n",
            "Epoch 15/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5547 - accuracy: 0.7230 - val_loss: 0.5475 - val_accuracy: 0.7310\n",
            "Epoch 16/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5378 - accuracy: 0.7420 - val_loss: 0.5198 - val_accuracy: 0.7600\n",
            "Epoch 17/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5215 - accuracy: 0.7455 - val_loss: 0.5573 - val_accuracy: 0.7360\n",
            "Epoch 18/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5004 - accuracy: 0.7600 - val_loss: 0.5535 - val_accuracy: 0.7330\n",
            "Epoch 19/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4914 - accuracy: 0.7625 - val_loss: 0.6683 - val_accuracy: 0.7160\n",
            "Epoch 20/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5015 - accuracy: 0.7495 - val_loss: 0.5145 - val_accuracy: 0.7620\n",
            "Epoch 21/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.4786 - accuracy: 0.7745 - val_loss: 0.5628 - val_accuracy: 0.7230\n",
            "Epoch 22/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.4872 - accuracy: 0.7805 - val_loss: 0.5899 - val_accuracy: 0.7380\n",
            "Epoch 23/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4589 - accuracy: 0.7815 - val_loss: 0.4883 - val_accuracy: 0.7860\n",
            "Epoch 24/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4441 - accuracy: 0.7880 - val_loss: 0.5251 - val_accuracy: 0.7570\n",
            "Epoch 25/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4520 - accuracy: 0.7910 - val_loss: 0.4877 - val_accuracy: 0.7650\n",
            "Epoch 26/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4341 - accuracy: 0.8120 - val_loss: 0.5679 - val_accuracy: 0.7540\n",
            "Epoch 27/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4368 - accuracy: 0.7985 - val_loss: 0.4583 - val_accuracy: 0.7950\n",
            "Epoch 28/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4102 - accuracy: 0.8270 - val_loss: 0.5142 - val_accuracy: 0.7720\n",
            "Epoch 29/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.4151 - accuracy: 0.8135 - val_loss: 0.7585 - val_accuracy: 0.6960\n",
            "Epoch 30/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4106 - accuracy: 0.8105 - val_loss: 0.5804 - val_accuracy: 0.7590\n",
            "Epoch 31/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4038 - accuracy: 0.8195 - val_loss: 0.5887 - val_accuracy: 0.7830\n",
            "Epoch 32/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.4019 - accuracy: 0.8150 - val_loss: 0.6743 - val_accuracy: 0.6860\n",
            "Epoch 33/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.3756 - accuracy: 0.8305 - val_loss: 0.4963 - val_accuracy: 0.7700\n",
            "Epoch 34/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.3773 - accuracy: 0.8295 - val_loss: 0.5638 - val_accuracy: 0.7790\n",
            "Epoch 35/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.3682 - accuracy: 0.8285 - val_loss: 0.5931 - val_accuracy: 0.7400\n",
            "Epoch 36/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3732 - accuracy: 0.8395 - val_loss: 0.4492 - val_accuracy: 0.8030\n",
            "Epoch 37/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3595 - accuracy: 0.8335 - val_loss: 0.4915 - val_accuracy: 0.8040\n",
            "Epoch 38/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.3561 - accuracy: 0.8410 - val_loss: 0.5781 - val_accuracy: 0.8000\n",
            "Epoch 39/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3306 - accuracy: 0.8565 - val_loss: 0.4687 - val_accuracy: 0.8080\n",
            "Epoch 40/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3256 - accuracy: 0.8560 - val_loss: 0.4413 - val_accuracy: 0.8290\n",
            "Epoch 41/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3056 - accuracy: 0.8705 - val_loss: 0.4884 - val_accuracy: 0.8050\n",
            "Epoch 42/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3235 - accuracy: 0.8660 - val_loss: 0.4894 - val_accuracy: 0.8110\n",
            "Epoch 43/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3023 - accuracy: 0.8665 - val_loss: 0.5449 - val_accuracy: 0.8000\n",
            "Epoch 44/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3163 - accuracy: 0.8650 - val_loss: 0.5750 - val_accuracy: 0.7890\n",
            "Epoch 45/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3156 - accuracy: 0.8640 - val_loss: 0.4412 - val_accuracy: 0.8230\n",
            "Epoch 46/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2676 - accuracy: 0.8825 - val_loss: 0.4489 - val_accuracy: 0.8240\n",
            "Epoch 47/60\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.2729 - accuracy: 0.8870 - val_loss: 0.5612 - val_accuracy: 0.7940\n",
            "Epoch 48/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2769 - accuracy: 0.8825 - val_loss: 0.4833 - val_accuracy: 0.8300\n",
            "Epoch 49/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2606 - accuracy: 0.8925 - val_loss: 0.5548 - val_accuracy: 0.8010\n",
            "Epoch 50/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2509 - accuracy: 0.8935 - val_loss: 0.4516 - val_accuracy: 0.8310\n",
            "Epoch 51/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2476 - accuracy: 0.8920 - val_loss: 0.5170 - val_accuracy: 0.8140\n",
            "Epoch 52/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2421 - accuracy: 0.9005 - val_loss: 0.6283 - val_accuracy: 0.8150\n",
            "Epoch 53/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2551 - accuracy: 0.8865 - val_loss: 0.7061 - val_accuracy: 0.7710\n",
            "Epoch 54/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2285 - accuracy: 0.9050 - val_loss: 0.5348 - val_accuracy: 0.8210\n",
            "Epoch 55/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2427 - accuracy: 0.9040 - val_loss: 0.7045 - val_accuracy: 0.7880\n",
            "Epoch 56/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2238 - accuracy: 0.9085 - val_loss: 0.6399 - val_accuracy: 0.8200\n",
            "Epoch 57/60\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2314 - accuracy: 0.9085 - val_loss: 0.4554 - val_accuracy: 0.8220\n",
            "Epoch 58/60\n",
            "63/63 [==============================] - 9s 131ms/step - loss: 0.2133 - accuracy: 0.9175 - val_loss: 0.6295 - val_accuracy: 0.8130\n",
            "Epoch 59/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2076 - accuracy: 0.9080 - val_loss: 0.5623 - val_accuracy: 0.8000\n",
            "Epoch 60/60\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2208 - accuracy: 0.9120 - val_loss: 0.7278 - val_accuracy: 0.7990\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=60,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP4vExqb_aDz"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFnQgDzU_aDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37eeecd1-8ad8-4666-bb15-298c6ca81d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 48ms/step - loss: 0.4591 - accuracy: 0.8120\n",
            "Test accuracy: 0.812\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8itqqaaylzau"
      },
      "source": [
        "### Using data augmentation with dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model performs the best here, with test loss of 0.4097. The accuracy is slightly worse than that of the augmentation only model, but minimizing the loss metric is our goal here."
      ],
      "metadata": {
        "id": "MCgN4GT2XM4L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbm1uwmMlzbC"
      },
      "source": [
        "**Define a data augmentation stage to add to an image model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EorOsQtdlzbC"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulY6TBEilzbD"
      },
      "source": [
        "**Defining a new convnet that includes image augmentation and dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PS6DDGZlzbD"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umss65EKlzbE"
      },
      "source": [
        "**Training the regularized convnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb5RbtE6lzbE",
        "outputId": "d4d45852-9faf-4812-d1c6-8a45c2b18fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 9s 119ms/step - loss: 0.7109 - accuracy: 0.5210 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.7252 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5100\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6846 - accuracy: 0.5740 - val_loss: 0.6853 - val_accuracy: 0.5190\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.7039 - accuracy: 0.5990 - val_loss: 0.6528 - val_accuracy: 0.6230\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.6597 - accuracy: 0.6070 - val_loss: 0.6492 - val_accuracy: 0.6180\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.6664 - accuracy: 0.6215 - val_loss: 0.6336 - val_accuracy: 0.6310\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6401 - accuracy: 0.6320 - val_loss: 0.6774 - val_accuracy: 0.6020\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.6284 - accuracy: 0.6555 - val_loss: 0.6445 - val_accuracy: 0.6300\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.6284 - accuracy: 0.6475 - val_loss: 0.6590 - val_accuracy: 0.6570\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.6063 - accuracy: 0.6700 - val_loss: 0.6491 - val_accuracy: 0.6820\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.5982 - accuracy: 0.6780 - val_loss: 0.5975 - val_accuracy: 0.6840\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5823 - accuracy: 0.6800 - val_loss: 0.5935 - val_accuracy: 0.7040\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5708 - accuracy: 0.7010 - val_loss: 0.5688 - val_accuracy: 0.7070\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5598 - accuracy: 0.7075 - val_loss: 0.5545 - val_accuracy: 0.7180\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5600 - accuracy: 0.7185 - val_loss: 0.5560 - val_accuracy: 0.7250\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5396 - accuracy: 0.7260 - val_loss: 0.5406 - val_accuracy: 0.7570\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.5395 - accuracy: 0.7355 - val_loss: 0.5417 - val_accuracy: 0.7380\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5239 - accuracy: 0.7435 - val_loss: 0.5393 - val_accuracy: 0.7570\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.5191 - accuracy: 0.7385 - val_loss: 0.5056 - val_accuracy: 0.7720\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5103 - accuracy: 0.7525 - val_loss: 0.5740 - val_accuracy: 0.7290\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4963 - accuracy: 0.7560 - val_loss: 0.5588 - val_accuracy: 0.7470\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.5013 - accuracy: 0.7535 - val_loss: 0.4996 - val_accuracy: 0.7660\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.5283 - accuracy: 0.7500 - val_loss: 0.5154 - val_accuracy: 0.7530\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4630 - accuracy: 0.7875 - val_loss: 0.5055 - val_accuracy: 0.7720\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4557 - accuracy: 0.7880 - val_loss: 0.5912 - val_accuracy: 0.7270\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.4672 - accuracy: 0.7770 - val_loss: 0.4721 - val_accuracy: 0.7870\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.4449 - accuracy: 0.7850 - val_loss: 0.4942 - val_accuracy: 0.7850\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4450 - accuracy: 0.7995 - val_loss: 0.4861 - val_accuracy: 0.7880\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4442 - accuracy: 0.8025 - val_loss: 0.4810 - val_accuracy: 0.8020\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.4356 - accuracy: 0.7995 - val_loss: 0.7516 - val_accuracy: 0.7010\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4263 - accuracy: 0.8065 - val_loss: 0.5693 - val_accuracy: 0.7610\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.4210 - accuracy: 0.8105 - val_loss: 0.8334 - val_accuracy: 0.6460\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.4086 - accuracy: 0.8045 - val_loss: 0.5082 - val_accuracy: 0.7800\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3989 - accuracy: 0.8165 - val_loss: 0.5074 - val_accuracy: 0.7880\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.3940 - accuracy: 0.8145 - val_loss: 0.6024 - val_accuracy: 0.7480\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.3863 - accuracy: 0.8215 - val_loss: 0.5539 - val_accuracy: 0.7730\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.3909 - accuracy: 0.8265 - val_loss: 0.5325 - val_accuracy: 0.7970\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.3826 - accuracy: 0.8285 - val_loss: 0.4833 - val_accuracy: 0.8240\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3753 - accuracy: 0.8340 - val_loss: 0.4369 - val_accuracy: 0.8160\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3650 - accuracy: 0.8355 - val_loss: 0.4201 - val_accuracy: 0.8280\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.3671 - accuracy: 0.8410 - val_loss: 0.4278 - val_accuracy: 0.8170\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3565 - accuracy: 0.8355 - val_loss: 0.4665 - val_accuracy: 0.8160\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3632 - accuracy: 0.8405 - val_loss: 0.4589 - val_accuracy: 0.8020\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3346 - accuracy: 0.8580 - val_loss: 0.4536 - val_accuracy: 0.8110\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3567 - accuracy: 0.8385 - val_loss: 0.4433 - val_accuracy: 0.8140\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.3327 - accuracy: 0.8550 - val_loss: 0.4766 - val_accuracy: 0.8010\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.3287 - accuracy: 0.8535 - val_loss: 0.4750 - val_accuracy: 0.7930\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3158 - accuracy: 0.8515 - val_loss: 0.6207 - val_accuracy: 0.7850\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.2959 - accuracy: 0.8745 - val_loss: 0.5704 - val_accuracy: 0.7920\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.3047 - accuracy: 0.8705 - val_loss: 0.4489 - val_accuracy: 0.8360\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3098 - accuracy: 0.8615 - val_loss: 0.4817 - val_accuracy: 0.8000\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.2864 - accuracy: 0.8840 - val_loss: 0.5341 - val_accuracy: 0.7640\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3024 - accuracy: 0.8705 - val_loss: 0.5052 - val_accuracy: 0.8290\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3121 - accuracy: 0.8690 - val_loss: 0.4826 - val_accuracy: 0.8170\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.2872 - accuracy: 0.8800 - val_loss: 0.5536 - val_accuracy: 0.8170\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.3004 - accuracy: 0.8755 - val_loss: 0.5626 - val_accuracy: 0.8160\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2854 - accuracy: 0.8925 - val_loss: 0.5051 - val_accuracy: 0.7960\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2666 - accuracy: 0.8900 - val_loss: 0.4826 - val_accuracy: 0.8300\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2583 - accuracy: 0.8935 - val_loss: 0.4629 - val_accuracy: 0.8380\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2514 - accuracy: 0.8865 - val_loss: 0.7974 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2511 - accuracy: 0.8895 - val_loss: 0.9003 - val_accuracy: 0.6900\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2665 - accuracy: 0.8970 - val_loss: 0.4654 - val_accuracy: 0.8410\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2579 - accuracy: 0.8865 - val_loss: 0.4823 - val_accuracy: 0.8160\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2484 - accuracy: 0.8900 - val_loss: 0.4437 - val_accuracy: 0.8260\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2456 - accuracy: 0.9005 - val_loss: 0.4976 - val_accuracy: 0.8300\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2565 - accuracy: 0.9015 - val_loss: 0.5991 - val_accuracy: 0.8160\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2491 - accuracy: 0.9020 - val_loss: 0.5822 - val_accuracy: 0.7700\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.2496 - accuracy: 0.8960 - val_loss: 0.5997 - val_accuracy: 0.8270\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2541 - accuracy: 0.9050 - val_loss: 0.5757 - val_accuracy: 0.8180\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2240 - accuracy: 0.9165 - val_loss: 0.4966 - val_accuracy: 0.8380\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2299 - accuracy: 0.9115 - val_loss: 0.4851 - val_accuracy: 0.8380\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2035 - accuracy: 0.9175 - val_loss: 0.6289 - val_accuracy: 0.8240\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2172 - accuracy: 0.9090 - val_loss: 0.7230 - val_accuracy: 0.8010\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2324 - accuracy: 0.9080 - val_loss: 0.4674 - val_accuracy: 0.8410\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.2050 - accuracy: 0.9155 - val_loss: 0.5577 - val_accuracy: 0.8350\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2047 - accuracy: 0.9160 - val_loss: 1.0441 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2156 - accuracy: 0.9235 - val_loss: 0.8541 - val_accuracy: 0.8210\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2196 - accuracy: 0.9100 - val_loss: 0.7548 - val_accuracy: 0.8350\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.1931 - accuracy: 0.9255 - val_loss: 0.6941 - val_accuracy: 0.8400\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1880 - accuracy: 0.9260 - val_loss: 0.9127 - val_accuracy: 0.8100\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2123 - accuracy: 0.9155 - val_loss: 0.6490 - val_accuracy: 0.8330\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 8s 120ms/step - loss: 0.1900 - accuracy: 0.9255 - val_loss: 0.6110 - val_accuracy: 0.8240\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2067 - accuracy: 0.9190 - val_loss: 0.7310 - val_accuracy: 0.8250\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2095 - accuracy: 0.9175 - val_loss: 0.4645 - val_accuracy: 0.8600\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1967 - accuracy: 0.9210 - val_loss: 0.5685 - val_accuracy: 0.8530\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.1983 - accuracy: 0.9290 - val_loss: 0.5448 - val_accuracy: 0.8510\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2081 - accuracy: 0.9260 - val_loss: 0.9019 - val_accuracy: 0.8340\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1823 - accuracy: 0.9280 - val_loss: 1.4876 - val_accuracy: 0.7740\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.1898 - accuracy: 0.9280 - val_loss: 0.6564 - val_accuracy: 0.8350\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.1923 - accuracy: 0.9230 - val_loss: 0.8288 - val_accuracy: 0.8240\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1861 - accuracy: 0.9330 - val_loss: 0.6599 - val_accuracy: 0.8450\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.1953 - accuracy: 0.9325 - val_loss: 0.5992 - val_accuracy: 0.8520\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.1809 - accuracy: 0.9330 - val_loss: 0.8699 - val_accuracy: 0.7960\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1750 - accuracy: 0.9320 - val_loss: 0.6205 - val_accuracy: 0.8560\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1951 - accuracy: 0.9245 - val_loss: 0.5763 - val_accuracy: 0.8160\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1989 - accuracy: 0.9345 - val_loss: 0.8058 - val_accuracy: 0.8190\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.1858 - accuracy: 0.9295 - val_loss: 0.6857 - val_accuracy: 0.8240\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.1688 - accuracy: 0.9355 - val_loss: 0.7417 - val_accuracy: 0.8470\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.2046 - accuracy: 0.9320 - val_loss: 0.6790 - val_accuracy: 0.8390\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.2062 - accuracy: 0.9195 - val_loss: 0.7134 - val_accuracy: 0.8120\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z29VWqOHlzbE"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9J0wnPXlzbF",
        "outputId": "efc12836-b560-4014-f715-7ebb09b5cb39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 48ms/step - loss: 0.4097 - accuracy: 0.8090\n",
            "Test accuracy: 0.809\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increasing the training sample size"
      ],
      "metadata": {
        "id": "lNZZzZ7jnjPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With more training data, we should expect better results. We keep using image augmentation and dropout here as we double the training set size to 2000 images. Validation and test sets are kept at 500 images each. The test loss is greatly reduced to 0.2817."
      ],
      "metadata": {
        "id": "BFg3ACAaXw4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Doubling sample size from 1000 to 2000"
      ],
      "metadata": {
        "id": "lAflMTxUn0Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_subset(\"train_2\", start_index=1000, end_index=3000)\n",
        "\n",
        "train_2_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train_2\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0lOOqH4nnuO",
        "outputId": "b59f322d-84dc-4020-98c5-5ed977579e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and evaluating model with image augmentation and dropout"
      ],
      "metadata": {
        "id": "kl7WASuRoOHr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Ph_CiUoeQp"
      },
      "source": [
        "**Defining a new convnet that includes image augmentation and dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3urE469NoeQz"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRspJOIHoeQz"
      },
      "source": [
        "**Training the regularized convnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNuKYw3KoeQz",
        "outputId": "040c00fc-919e-4a84-c952-906d2dcc60a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 15s 106ms/step - loss: 0.7141 - accuracy: 0.5400 - val_loss: 0.6826 - val_accuracy: 0.5130\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.6770 - accuracy: 0.6020 - val_loss: 0.6852 - val_accuracy: 0.5610\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.6598 - accuracy: 0.6170 - val_loss: 0.6353 - val_accuracy: 0.6520\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.6431 - accuracy: 0.6435 - val_loss: 0.6694 - val_accuracy: 0.6110\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.6246 - accuracy: 0.6530 - val_loss: 0.5772 - val_accuracy: 0.7080\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.6242 - accuracy: 0.6643 - val_loss: 0.6139 - val_accuracy: 0.6830\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.6044 - accuracy: 0.6785 - val_loss: 0.5679 - val_accuracy: 0.7030\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.5971 - accuracy: 0.6827 - val_loss: 0.5814 - val_accuracy: 0.6810\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.5702 - accuracy: 0.7010 - val_loss: 0.5093 - val_accuracy: 0.7640\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.5571 - accuracy: 0.7172 - val_loss: 0.5080 - val_accuracy: 0.7670\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.5479 - accuracy: 0.7207 - val_loss: 0.5260 - val_accuracy: 0.7550\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.5240 - accuracy: 0.7385 - val_loss: 0.5594 - val_accuracy: 0.7150\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.5250 - accuracy: 0.7380 - val_loss: 0.5147 - val_accuracy: 0.7410\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.5092 - accuracy: 0.7517 - val_loss: 0.5084 - val_accuracy: 0.7620\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.4948 - accuracy: 0.7592 - val_loss: 0.4734 - val_accuracy: 0.7840\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.4801 - accuracy: 0.7730 - val_loss: 0.5226 - val_accuracy: 0.7400\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.4721 - accuracy: 0.7788 - val_loss: 0.4577 - val_accuracy: 0.7950\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.4672 - accuracy: 0.7782 - val_loss: 0.4775 - val_accuracy: 0.7830\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.4585 - accuracy: 0.7895 - val_loss: 0.4686 - val_accuracy: 0.8010\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.4509 - accuracy: 0.7878 - val_loss: 0.4217 - val_accuracy: 0.8200\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.4424 - accuracy: 0.8010 - val_loss: 0.5619 - val_accuracy: 0.7410\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.4297 - accuracy: 0.7985 - val_loss: 0.4847 - val_accuracy: 0.7750\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.4188 - accuracy: 0.8110 - val_loss: 0.3774 - val_accuracy: 0.8360\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.4039 - accuracy: 0.8155 - val_loss: 0.4255 - val_accuracy: 0.8260\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 14s 105ms/step - loss: 0.3956 - accuracy: 0.8202 - val_loss: 0.3526 - val_accuracy: 0.8480\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3843 - accuracy: 0.8278 - val_loss: 0.5335 - val_accuracy: 0.8030\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3810 - accuracy: 0.8292 - val_loss: 0.4031 - val_accuracy: 0.8370\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3761 - accuracy: 0.8378 - val_loss: 0.3747 - val_accuracy: 0.8370\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3696 - accuracy: 0.8370 - val_loss: 0.3953 - val_accuracy: 0.8470\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3549 - accuracy: 0.8435 - val_loss: 0.3827 - val_accuracy: 0.8520\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3603 - accuracy: 0.8353 - val_loss: 0.4748 - val_accuracy: 0.8030\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3440 - accuracy: 0.8522 - val_loss: 0.3438 - val_accuracy: 0.8530\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3470 - accuracy: 0.8562 - val_loss: 0.3541 - val_accuracy: 0.8750\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3503 - accuracy: 0.8497 - val_loss: 0.3509 - val_accuracy: 0.8520\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3249 - accuracy: 0.8625 - val_loss: 0.3764 - val_accuracy: 0.8470\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3340 - accuracy: 0.8587 - val_loss: 0.3525 - val_accuracy: 0.8690\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3368 - accuracy: 0.8572 - val_loss: 0.5338 - val_accuracy: 0.7450\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3220 - accuracy: 0.8595 - val_loss: 0.6332 - val_accuracy: 0.8190\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3039 - accuracy: 0.8733 - val_loss: 0.4335 - val_accuracy: 0.8430\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3232 - accuracy: 0.8615 - val_loss: 0.4047 - val_accuracy: 0.8500\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3094 - accuracy: 0.8730 - val_loss: 0.3552 - val_accuracy: 0.8670\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.2948 - accuracy: 0.8765 - val_loss: 0.3168 - val_accuracy: 0.8690\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3166 - accuracy: 0.8687 - val_loss: 0.4041 - val_accuracy: 0.8510\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3150 - accuracy: 0.8683 - val_loss: 0.3647 - val_accuracy: 0.8860\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3044 - accuracy: 0.8808 - val_loss: 0.3537 - val_accuracy: 0.8610\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3108 - accuracy: 0.8705 - val_loss: 0.3276 - val_accuracy: 0.8760\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3121 - accuracy: 0.8700 - val_loss: 0.2879 - val_accuracy: 0.8800\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3095 - accuracy: 0.8668 - val_loss: 0.2960 - val_accuracy: 0.8790\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3136 - accuracy: 0.8692 - val_loss: 0.3968 - val_accuracy: 0.8450\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3105 - accuracy: 0.8692 - val_loss: 0.4593 - val_accuracy: 0.8360\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3199 - accuracy: 0.8690 - val_loss: 0.2546 - val_accuracy: 0.8940\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3009 - accuracy: 0.8758 - val_loss: 0.2742 - val_accuracy: 0.8870\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3091 - accuracy: 0.8810 - val_loss: 0.3605 - val_accuracy: 0.8580\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.2857 - accuracy: 0.8873 - val_loss: 0.3125 - val_accuracy: 0.8800\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.2796 - accuracy: 0.8913 - val_loss: 0.2924 - val_accuracy: 0.8800\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.2785 - accuracy: 0.8903 - val_loss: 0.3250 - val_accuracy: 0.8610\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3099 - accuracy: 0.8820 - val_loss: 0.3290 - val_accuracy: 0.8670\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3031 - accuracy: 0.8770 - val_loss: 0.3245 - val_accuracy: 0.8870\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.2922 - accuracy: 0.8815 - val_loss: 0.3873 - val_accuracy: 0.8580\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.2977 - accuracy: 0.8815 - val_loss: 0.3346 - val_accuracy: 0.8900\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3086 - accuracy: 0.8773 - val_loss: 0.3446 - val_accuracy: 0.8830\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3289 - accuracy: 0.8745 - val_loss: 0.5843 - val_accuracy: 0.8670\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3075 - accuracy: 0.8752 - val_loss: 0.3133 - val_accuracy: 0.8700\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3017 - accuracy: 0.8775 - val_loss: 0.4011 - val_accuracy: 0.8830\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3223 - accuracy: 0.8683 - val_loss: 0.5898 - val_accuracy: 0.8370\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3154 - accuracy: 0.8723 - val_loss: 0.4501 - val_accuracy: 0.8930\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3001 - accuracy: 0.8835 - val_loss: 0.2994 - val_accuracy: 0.8840\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.2949 - accuracy: 0.8838 - val_loss: 0.3967 - val_accuracy: 0.8640\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3128 - accuracy: 0.8755 - val_loss: 0.4448 - val_accuracy: 0.8540\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3042 - accuracy: 0.8800 - val_loss: 0.4269 - val_accuracy: 0.8510\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3147 - accuracy: 0.8820 - val_loss: 0.5176 - val_accuracy: 0.8580\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3088 - accuracy: 0.8825 - val_loss: 0.3917 - val_accuracy: 0.8450\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3275 - accuracy: 0.8692 - val_loss: 0.5102 - val_accuracy: 0.8560\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 14s 105ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.4713 - val_accuracy: 0.9020\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.2987 - accuracy: 0.8788 - val_loss: 0.7975 - val_accuracy: 0.8820\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3116 - accuracy: 0.8767 - val_loss: 0.3951 - val_accuracy: 0.8650\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 14s 105ms/step - loss: 0.2911 - accuracy: 0.8852 - val_loss: 0.3945 - val_accuracy: 0.8690\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.2944 - accuracy: 0.8800 - val_loss: 0.4029 - val_accuracy: 0.8830\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3217 - accuracy: 0.8788 - val_loss: 0.2996 - val_accuracy: 0.8920\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3133 - accuracy: 0.8802 - val_loss: 0.3835 - val_accuracy: 0.8710\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3312 - accuracy: 0.8652 - val_loss: 0.3540 - val_accuracy: 0.8400\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3219 - accuracy: 0.8767 - val_loss: 1.1418 - val_accuracy: 0.7330\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3172 - accuracy: 0.8777 - val_loss: 0.3414 - val_accuracy: 0.8810\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3180 - accuracy: 0.8823 - val_loss: 0.3248 - val_accuracy: 0.8900\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3416 - accuracy: 0.8777 - val_loss: 0.4207 - val_accuracy: 0.8730\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3350 - accuracy: 0.8767 - val_loss: 0.4614 - val_accuracy: 0.8100\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3237 - accuracy: 0.8795 - val_loss: 0.4343 - val_accuracy: 0.8760\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3356 - accuracy: 0.8652 - val_loss: 0.5082 - val_accuracy: 0.8470\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3736 - accuracy: 0.8543 - val_loss: 0.3270 - val_accuracy: 0.8850\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3687 - accuracy: 0.8587 - val_loss: 0.2953 - val_accuracy: 0.8900\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3622 - accuracy: 0.8620 - val_loss: 0.4168 - val_accuracy: 0.8760\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3279 - accuracy: 0.8755 - val_loss: 0.3604 - val_accuracy: 0.8900\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 14s 106ms/step - loss: 0.3605 - accuracy: 0.8610 - val_loss: 0.3418 - val_accuracy: 0.8530\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 13s 105ms/step - loss: 0.3508 - accuracy: 0.8587 - val_loss: 0.5973 - val_accuracy: 0.8080\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3618 - accuracy: 0.8608 - val_loss: 0.3676 - val_accuracy: 0.8760\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3679 - accuracy: 0.8618 - val_loss: 0.4228 - val_accuracy: 0.8660\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3403 - accuracy: 0.8683 - val_loss: 1.0760 - val_accuracy: 0.7170\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3462 - accuracy: 0.8675 - val_loss: 0.4507 - val_accuracy: 0.8630\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3703 - accuracy: 0.8540 - val_loss: 0.5558 - val_accuracy: 0.8320\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3720 - accuracy: 0.8555 - val_loss: 0.4050 - val_accuracy: 0.8660\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_2000_samples.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_2_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR28BCDLoeQ0"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCw3wWBWoeQ0",
        "outputId": "822143b7-ebe7-4dc1-e2ab-f80c8e909496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 50ms/step - loss: 0.2817 - accuracy: 0.8790\n",
            "Test accuracy: 0.879\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_2000_samples.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further increasing training sample size"
      ],
      "metadata": {
        "id": "y8S4TKWw8VtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If more training data makes for a better model, why stop at 2000? Here we increase the training sample to be nearly as large as possible, keeping validation and test samples the same. Again, we apply data augmentation and dropout, and we end up with a test loss of just 0.2467."
      ],
      "metadata": {
        "id": "tChJmltiYwYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Increasing sample size to 10000"
      ],
      "metadata": {
        "id": "Qj99CRRe8VtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_subset(\"train_3\", start_index=1000, end_index=11000)\n",
        "\n",
        "train_3_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train_3\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe6f310-f0e3-4a24-f231-e23edc37b42c",
        "id": "opzBYXuM8VtV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and evaluating model with image augmentation and dropout"
      ],
      "metadata": {
        "id": "5rtWagBt8VtV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP9PmHnM8VtW"
      },
      "source": [
        "**Defining a new convnet that includes image augmentation and dropout**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0aIkHXk8VtW"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJgP7ARV8VtW"
      },
      "source": [
        "**Training the regularized convnet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918fccc7-6b50-484d-9f16-69b5f7c5ca51",
        "id": "NPvghY-Q8VtW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "625/625 [==============================] - 62s 95ms/step - loss: 0.6749 - accuracy: 0.6044 - val_loss: 0.5635 - val_accuracy: 0.7300\n",
            "Epoch 2/70\n",
            "625/625 [==============================] - 59s 95ms/step - loss: 0.5622 - accuracy: 0.7092 - val_loss: 0.4954 - val_accuracy: 0.7610\n",
            "Epoch 3/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.4963 - accuracy: 0.7642 - val_loss: 0.4068 - val_accuracy: 0.8080\n",
            "Epoch 4/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.4498 - accuracy: 0.7889 - val_loss: 0.3636 - val_accuracy: 0.8330\n",
            "Epoch 5/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.4017 - accuracy: 0.8188 - val_loss: 0.4810 - val_accuracy: 0.7710\n",
            "Epoch 6/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.3697 - accuracy: 0.8367 - val_loss: 0.2844 - val_accuracy: 0.8720\n",
            "Epoch 7/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.3504 - accuracy: 0.8476 - val_loss: 0.2798 - val_accuracy: 0.8780\n",
            "Epoch 8/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.3413 - accuracy: 0.8522 - val_loss: 0.2288 - val_accuracy: 0.8950\n",
            "Epoch 9/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.3394 - accuracy: 0.8547 - val_loss: 0.2289 - val_accuracy: 0.8960\n",
            "Epoch 10/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.3351 - accuracy: 0.8582 - val_loss: 0.2491 - val_accuracy: 0.8810\n",
            "Epoch 11/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.3497 - accuracy: 0.8506 - val_loss: 0.2683 - val_accuracy: 0.8780\n",
            "Epoch 12/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.3660 - accuracy: 0.8503 - val_loss: 0.2425 - val_accuracy: 0.8950\n",
            "Epoch 13/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.3543 - accuracy: 0.8521 - val_loss: 0.2577 - val_accuracy: 0.9010\n",
            "Epoch 14/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.3969 - accuracy: 0.8394 - val_loss: 0.2296 - val_accuracy: 0.9070\n",
            "Epoch 15/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.3985 - accuracy: 0.8324 - val_loss: 0.3747 - val_accuracy: 0.8360\n",
            "Epoch 16/70\n",
            "625/625 [==============================] - 61s 97ms/step - loss: 0.4138 - accuracy: 0.8291 - val_loss: 0.3444 - val_accuracy: 0.8620\n",
            "Epoch 17/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.4641 - accuracy: 0.8268 - val_loss: 0.2467 - val_accuracy: 0.8910\n",
            "Epoch 18/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.4410 - accuracy: 0.8135 - val_loss: 0.3154 - val_accuracy: 0.8470\n",
            "Epoch 19/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.4859 - accuracy: 0.8088 - val_loss: 0.3371 - val_accuracy: 0.8620\n",
            "Epoch 20/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.5153 - accuracy: 0.7944 - val_loss: 0.2690 - val_accuracy: 0.8980\n",
            "Epoch 21/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.5090 - accuracy: 0.8011 - val_loss: 0.3357 - val_accuracy: 0.8740\n",
            "Epoch 22/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.5370 - accuracy: 0.7953 - val_loss: 0.4099 - val_accuracy: 0.8010\n",
            "Epoch 23/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.5235 - accuracy: 0.7774 - val_loss: 0.3335 - val_accuracy: 0.8620\n",
            "Epoch 24/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.6403 - accuracy: 0.7537 - val_loss: 0.6403 - val_accuracy: 0.7670\n",
            "Epoch 25/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.6265 - accuracy: 0.7619 - val_loss: 0.3683 - val_accuracy: 0.8280\n",
            "Epoch 26/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6462 - accuracy: 0.7624 - val_loss: 0.4279 - val_accuracy: 0.8060\n",
            "Epoch 27/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6456 - accuracy: 0.7539 - val_loss: 0.4746 - val_accuracy: 0.8720\n",
            "Epoch 28/70\n",
            "625/625 [==============================] - 59s 95ms/step - loss: 0.6741 - accuracy: 0.7513 - val_loss: 0.4428 - val_accuracy: 0.8070\n",
            "Epoch 29/70\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.6368 - accuracy: 0.7522 - val_loss: 0.5945 - val_accuracy: 0.7760\n",
            "Epoch 30/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.6576 - accuracy: 0.7438 - val_loss: 0.3797 - val_accuracy: 0.8330\n",
            "Epoch 31/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.6488 - accuracy: 0.7437 - val_loss: 0.4209 - val_accuracy: 0.8090\n",
            "Epoch 32/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6585 - accuracy: 0.7285 - val_loss: 6.1037 - val_accuracy: 0.5840\n",
            "Epoch 33/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.7301 - accuracy: 0.7344 - val_loss: 0.4377 - val_accuracy: 0.8020\n",
            "Epoch 34/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.6838 - accuracy: 0.7223 - val_loss: 34.7661 - val_accuracy: 0.5230\n",
            "Epoch 35/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.7482 - accuracy: 0.7398 - val_loss: 0.3953 - val_accuracy: 0.8270\n",
            "Epoch 36/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6454 - accuracy: 0.7384 - val_loss: 0.4696 - val_accuracy: 0.8300\n",
            "Epoch 37/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 1.0824 - accuracy: 0.7387 - val_loss: 0.4929 - val_accuracy: 0.7980\n",
            "Epoch 38/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.6721 - accuracy: 0.7452 - val_loss: 0.4164 - val_accuracy: 0.8550\n",
            "Epoch 39/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.6374 - accuracy: 0.7404 - val_loss: 0.5398 - val_accuracy: 0.7290\n",
            "Epoch 40/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6330 - accuracy: 0.7161 - val_loss: 0.4586 - val_accuracy: 0.8360\n",
            "Epoch 41/70\n",
            "625/625 [==============================] - 60s 95ms/step - loss: 0.6527 - accuracy: 0.7359 - val_loss: 0.4034 - val_accuracy: 0.8270\n",
            "Epoch 42/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6384 - accuracy: 0.7149 - val_loss: 0.4524 - val_accuracy: 0.7770\n",
            "Epoch 43/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.6872 - accuracy: 0.7233 - val_loss: 1.4537 - val_accuracy: 0.6780\n",
            "Epoch 44/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.6392 - accuracy: 0.7203 - val_loss: 0.6494 - val_accuracy: 0.8120\n",
            "Epoch 45/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.5981 - accuracy: 0.7359 - val_loss: 0.4933 - val_accuracy: 0.8190\n",
            "Epoch 46/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.7177 - accuracy: 0.7185 - val_loss: 0.4481 - val_accuracy: 0.8040\n",
            "Epoch 47/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.7015 - accuracy: 0.7039 - val_loss: 0.5525 - val_accuracy: 0.7690\n",
            "Epoch 48/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.6862 - accuracy: 0.7116 - val_loss: 0.4656 - val_accuracy: 0.8150\n",
            "Epoch 49/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6435 - accuracy: 0.7154 - val_loss: 0.5918 - val_accuracy: 0.6130\n",
            "Epoch 50/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.6606 - accuracy: 0.6989 - val_loss: 0.5143 - val_accuracy: 0.7950\n",
            "Epoch 51/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6387 - accuracy: 0.6960 - val_loss: 0.5321 - val_accuracy: 0.7880\n",
            "Epoch 52/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6848 - accuracy: 0.7107 - val_loss: 0.5143 - val_accuracy: 0.8120\n",
            "Epoch 53/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.7195 - accuracy: 0.6934 - val_loss: 0.4130 - val_accuracy: 0.8040\n",
            "Epoch 54/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6599 - accuracy: 0.6956 - val_loss: 0.4664 - val_accuracy: 0.8070\n",
            "Epoch 55/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6745 - accuracy: 0.6969 - val_loss: 0.5642 - val_accuracy: 0.7410\n",
            "Epoch 56/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.6873 - accuracy: 0.6995 - val_loss: 0.5460 - val_accuracy: 0.7670\n",
            "Epoch 57/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6612 - accuracy: 0.7107 - val_loss: 0.4902 - val_accuracy: 0.7900\n",
            "Epoch 58/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.7191 - accuracy: 0.7153 - val_loss: 0.7007 - val_accuracy: 0.8080\n",
            "Epoch 59/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.7568 - accuracy: 0.7114 - val_loss: 0.4812 - val_accuracy: 0.8050\n",
            "Epoch 60/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.6569 - accuracy: 0.7034 - val_loss: 0.5901 - val_accuracy: 0.6850\n",
            "Epoch 61/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.7467 - accuracy: 0.6611 - val_loss: 0.5518 - val_accuracy: 0.6830\n",
            "Epoch 62/70\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.9585 - accuracy: 0.6927 - val_loss: 0.7958 - val_accuracy: 0.7800\n",
            "Epoch 63/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.7131 - accuracy: 0.6938 - val_loss: 0.5884 - val_accuracy: 0.7690\n",
            "Epoch 64/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.8138 - accuracy: 0.7020 - val_loss: 1.7074 - val_accuracy: 0.7970\n",
            "Epoch 65/70\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.8443 - accuracy: 0.6925 - val_loss: 0.5717 - val_accuracy: 0.6750\n",
            "Epoch 66/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.7222 - accuracy: 0.6790 - val_loss: 0.5742 - val_accuracy: 0.7640\n",
            "Epoch 67/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.6781 - accuracy: 0.6775 - val_loss: 1.0909 - val_accuracy: 0.7740\n",
            "Epoch 68/70\n",
            "625/625 [==============================] - 59s 93ms/step - loss: 0.6627 - accuracy: 0.6805 - val_loss: 0.4527 - val_accuracy: 0.7810\n",
            "Epoch 69/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.6999 - accuracy: 0.6968 - val_loss: 0.6586 - val_accuracy: 0.7300\n",
            "Epoch 70/70\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.7047 - accuracy: 0.6665 - val_loss: 0.5383 - val_accuracy: 0.7680\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_10000_samples.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_3_dataset,\n",
        "    epochs=70,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLsL_N3p8VtX"
      },
      "source": [
        "**Evaluating the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a9db6c-465f-40e0-ba42-b1960c63cf89",
        "id": "Ek5ZJPyw8VtX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 50ms/step - loss: 0.2467 - accuracy: 0.8990\n",
            "Test accuracy: 0.899\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_10000_samples.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqaBlQtD_aD0"
      },
      "source": [
        "# Leveraging a pretrained model with Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, we are starting to see diminishing returns with just increasing sample size. Let us use a pretrained model. We will allow to model to fine tune the last four layers."
      ],
      "metadata": {
        "id": "PqljdHBbZQKU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kkYzWnu_aD0"
      },
      "source": [
        "## Using a small sample size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start again with a training set size of 1000 images. We achieve a test loss of just 0.1842, already significantly lower than what we were able to achieve by training a model from scratch."
      ],
      "metadata": {
        "id": "2oy4JhBWZ9J9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fFq6cdn_aD0"
      },
      "source": [
        "**Instantiating the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyAqRx5x_aD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ef108c-268b-406e-9c85-f52d3f56e27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ymez2R_aD5"
      },
      "source": [
        "**Instantiating and freezing the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS0uPIdg_aD5"
      },
      "outputs": [],
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "\n",
        "# Freeze all but last four layers\n",
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVyzpso__aD7"
      },
      "source": [
        "**Adding a data augmentation stage and a classifier to the convolutional base and fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llx_IYUO_aD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d90eb90-8f6a-4570-8237-5d14eada1dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 30s 399ms/step - loss: 2.9432 - accuracy: 0.7885 - val_loss: 0.7741 - val_accuracy: 0.9160\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 1.0372 - accuracy: 0.8890 - val_loss: 0.3983 - val_accuracy: 0.9430\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.6886 - accuracy: 0.9070 - val_loss: 0.3178 - val_accuracy: 0.9540\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.4133 - accuracy: 0.9310 - val_loss: 0.2519 - val_accuracy: 0.9570\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 23s 362ms/step - loss: 0.3141 - accuracy: 0.9430 - val_loss: 0.2132 - val_accuracy: 0.9620\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.2033 - accuracy: 0.9490 - val_loss: 0.1901 - val_accuracy: 0.9600\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 23s 354ms/step - loss: 0.1625 - accuracy: 0.9590 - val_loss: 0.2281 - val_accuracy: 0.9630\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.1321 - accuracy: 0.9645 - val_loss: 0.2312 - val_accuracy: 0.9630\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.1346 - accuracy: 0.9640 - val_loss: 0.2252 - val_accuracy: 0.9660\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.1086 - accuracy: 0.9715 - val_loss: 0.1888 - val_accuracy: 0.9700\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0976 - accuracy: 0.9750 - val_loss: 0.2025 - val_accuracy: 0.9650\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 23s 354ms/step - loss: 0.0763 - accuracy: 0.9780 - val_loss: 0.2390 - val_accuracy: 0.9690\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0601 - accuracy: 0.9830 - val_loss: 0.2428 - val_accuracy: 0.9730\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 23s 356ms/step - loss: 0.0495 - accuracy: 0.9865 - val_loss: 0.2184 - val_accuracy: 0.9690\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 23s 354ms/step - loss: 0.0510 - accuracy: 0.9860 - val_loss: 0.2537 - val_accuracy: 0.9700\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 23s 354ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.2368 - val_accuracy: 0.9680\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 0.2506 - val_accuracy: 0.9710\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0551 - accuracy: 0.9845 - val_loss: 0.2648 - val_accuracy: 0.9680\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0523 - accuracy: 0.9845 - val_loss: 0.2552 - val_accuracy: 0.9670\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 22s 352ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.3389 - val_accuracy: 0.9720\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 23s 356ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.2744 - val_accuracy: 0.9700\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 0.2618 - val_accuracy: 0.9680\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.2622 - val_accuracy: 0.9690\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.2989 - val_accuracy: 0.9690\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.2803 - val_accuracy: 0.9750\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.2723 - val_accuracy: 0.9730\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.3091 - val_accuracy: 0.9750\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0331 - accuracy: 0.9930 - val_loss: 0.2639 - val_accuracy: 0.9720\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 23s 355ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.2673 - val_accuracy: 0.9740\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 22s 351ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.2492 - val_accuracy: 0.9740\n"
          ]
        }
      ],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning_1000_samples.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo-78OY2_aD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854cd733-7523-40b9-eef6-8ce745ff99d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 7s 207ms/step - loss: 0.1842 - accuracy: 0.9720\n",
            "Test accuracy: 0.972\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"fine_tuning_1000_samples.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aspFPGjKgGNj"
      },
      "source": [
        "## Increasing training sample size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start improving the model by increasing the training sample size to 2000 images. However, this actually causes the test loss to slightly increase to 0.1877. "
      ],
      "metadata": {
        "id": "Xzncqk2eamLM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj70unp4gGN3"
      },
      "source": [
        "**Instantiating the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kODspKa5gGN4"
      },
      "outputs": [],
      "source": [
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e46AQZNugGN5"
      },
      "source": [
        "**Instantiating and freezing the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh-EH2uKgGN5"
      },
      "outputs": [],
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "\n",
        "# Freeze all but last four layers\n",
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbPdDUVxgGN6"
      },
      "source": [
        "**Adding a data augmentation stage and a classifier to the convolutional base and fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPyegruJgGN6",
        "outputId": "da600bf6-696b-4be6-9098-802bb3541a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "125/125 [==============================] - 40s 303ms/step - loss: 2.7086 - accuracy: 0.8055 - val_loss: 0.5192 - val_accuracy: 0.9450\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.5542 - accuracy: 0.9155 - val_loss: 0.3109 - val_accuracy: 0.9600\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.3550 - accuracy: 0.9237 - val_loss: 0.2043 - val_accuracy: 0.9690\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.2063 - accuracy: 0.9423 - val_loss: 0.1849 - val_accuracy: 0.9690\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.1588 - accuracy: 0.9523 - val_loss: 0.1638 - val_accuracy: 0.9760\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.1531 - accuracy: 0.9575 - val_loss: 0.1860 - val_accuracy: 0.9680\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.1335 - accuracy: 0.9575 - val_loss: 0.1552 - val_accuracy: 0.9760\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.0969 - accuracy: 0.9660 - val_loss: 0.1550 - val_accuracy: 0.9740\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.1006 - accuracy: 0.9703 - val_loss: 0.1697 - val_accuracy: 0.9770\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.0863 - accuracy: 0.9732 - val_loss: 0.1548 - val_accuracy: 0.9750\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 38s 301ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.1734 - val_accuracy: 0.9800\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 38s 302ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 0.1641 - val_accuracy: 0.9730\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 38s 303ms/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 0.1474 - val_accuracy: 0.9790\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 38s 301ms/step - loss: 0.0528 - accuracy: 0.9812 - val_loss: 0.1563 - val_accuracy: 0.9770\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 38s 301ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 0.1551 - val_accuracy: 0.9790\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.1784 - val_accuracy: 0.9810\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0477 - accuracy: 0.9877 - val_loss: 0.1551 - val_accuracy: 0.9790\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0514 - accuracy: 0.9855 - val_loss: 0.2090 - val_accuracy: 0.9750\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.2089 - val_accuracy: 0.9740\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.1792 - val_accuracy: 0.9780\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0246 - accuracy: 0.9910 - val_loss: 0.1745 - val_accuracy: 0.9810\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.1570 - val_accuracy: 0.9830\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.2002 - val_accuracy: 0.9780\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 38s 299ms/step - loss: 0.0286 - accuracy: 0.9920 - val_loss: 0.1840 - val_accuracy: 0.9770\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 38s 299ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.2259 - val_accuracy: 0.9790\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.1568 - val_accuracy: 0.9810\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.2029 - val_accuracy: 0.9810\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.2063 - val_accuracy: 0.9770\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.2281 - val_accuracy: 0.9790\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 38s 300ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.2523 - val_accuracy: 0.9720\n"
          ]
        }
      ],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning_2000_samples.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_2_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqaT8GlHgGN8",
        "outputId": "b0aae1b0-8401-4239-c253-06b31943199e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 7s 207ms/step - loss: 0.1877 - accuracy: 0.9780\n",
            "Test accuracy: 0.978\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"fine_tuning_2000_samples.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a32EFFqxgHD6"
      },
      "source": [
        "## Further increasing training sample size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, more training data should make for a better deep learning model. Although we didn't see it last time, we shouldn't give up on that notion. Here, we increasing the training set size to 10,000 images and see the lowest test loss yet: 0.0777. "
      ],
      "metadata": {
        "id": "IH87nikxbCyJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qbIelRWgHD7"
      },
      "source": [
        "**Instantiating the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euCFDRzfgHD8"
      },
      "outputs": [],
      "source": [
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm4Zf6VIgHD8"
      },
      "source": [
        "**Instantiating and freezing the VGG16 convolutional base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz14oW1SgHD9"
      },
      "outputs": [],
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "\n",
        "# Freeze all but last four layers\n",
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUrCUfNVgHD9"
      },
      "source": [
        "**Adding a data augmentation stage and a classifier to the convolutional base and fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kS0GY30gHD-",
        "outputId": "8d3b74ee-1adf-49b7-c60c-5762212df7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "625/625 [==============================] - 163s 257ms/step - loss: 0.8207 - accuracy: 0.8939 - val_loss: 0.1033 - val_accuracy: 0.9690\n",
            "Epoch 2/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.1503 - accuracy: 0.9489 - val_loss: 0.0899 - val_accuracy: 0.9720\n",
            "Epoch 3/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.1074 - accuracy: 0.9639 - val_loss: 0.1100 - val_accuracy: 0.9800\n",
            "Epoch 4/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0999 - accuracy: 0.9686 - val_loss: 0.1379 - val_accuracy: 0.9780\n",
            "Epoch 5/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0878 - accuracy: 0.9710 - val_loss: 0.1813 - val_accuracy: 0.9820\n",
            "Epoch 6/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.1688 - val_accuracy: 0.9800\n",
            "Epoch 7/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0807 - accuracy: 0.9759 - val_loss: 0.1729 - val_accuracy: 0.9820\n",
            "Epoch 8/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.1921 - val_accuracy: 0.9770\n",
            "Epoch 9/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0849 - accuracy: 0.9754 - val_loss: 0.1938 - val_accuracy: 0.9800\n",
            "Epoch 10/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0807 - accuracy: 0.9761 - val_loss: 0.2607 - val_accuracy: 0.9780\n",
            "Epoch 11/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0768 - accuracy: 0.9779 - val_loss: 0.2243 - val_accuracy: 0.9790\n",
            "Epoch 12/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0664 - accuracy: 0.9792 - val_loss: 0.2010 - val_accuracy: 0.9820\n",
            "Epoch 13/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0761 - accuracy: 0.9788 - val_loss: 0.2280 - val_accuracy: 0.9830\n",
            "Epoch 14/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0797 - accuracy: 0.9781 - val_loss: 0.1951 - val_accuracy: 0.9810\n",
            "Epoch 15/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0814 - accuracy: 0.9772 - val_loss: 0.2892 - val_accuracy: 0.9840\n",
            "Epoch 16/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0671 - accuracy: 0.9801 - val_loss: 0.2822 - val_accuracy: 0.9800\n",
            "Epoch 17/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0776 - accuracy: 0.9784 - val_loss: 0.2341 - val_accuracy: 0.9810\n",
            "Epoch 18/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0705 - accuracy: 0.9801 - val_loss: 0.3436 - val_accuracy: 0.9800\n",
            "Epoch 19/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0802 - accuracy: 0.9774 - val_loss: 0.3659 - val_accuracy: 0.9790\n",
            "Epoch 20/30\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 0.0775 - accuracy: 0.9797 - val_loss: 0.3121 - val_accuracy: 0.9830\n",
            "Epoch 21/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0777 - accuracy: 0.9782 - val_loss: 0.2838 - val_accuracy: 0.9780\n",
            "Epoch 22/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0795 - accuracy: 0.9779 - val_loss: 0.1831 - val_accuracy: 0.9780\n",
            "Epoch 23/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0781 - accuracy: 0.9797 - val_loss: 0.3246 - val_accuracy: 0.9810\n",
            "Epoch 24/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0778 - accuracy: 0.9792 - val_loss: 0.4518 - val_accuracy: 0.9860\n",
            "Epoch 25/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0778 - accuracy: 0.9801 - val_loss: 0.2893 - val_accuracy: 0.9820\n",
            "Epoch 26/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0862 - accuracy: 0.9802 - val_loss: 0.2946 - val_accuracy: 0.9800\n",
            "Epoch 27/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0871 - accuracy: 0.9795 - val_loss: 0.3954 - val_accuracy: 0.9760\n",
            "Epoch 28/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0778 - accuracy: 0.9795 - val_loss: 0.4795 - val_accuracy: 0.9810\n",
            "Epoch 29/30\n",
            "625/625 [==============================] - 161s 256ms/step - loss: 0.0864 - accuracy: 0.9791 - val_loss: 0.3933 - val_accuracy: 0.9810\n",
            "Epoch 30/30\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 0.0963 - accuracy: 0.9764 - val_loss: 0.2526 - val_accuracy: 0.9730\n"
          ]
        }
      ],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning_10000_samples.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_3_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnvTDdBPgHD_",
        "outputId": "36f2466e-ced3-48a1-b127-c71f86dae863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 7s 208ms/step - loss: 0.0777 - accuracy: 0.9720\n",
            "Test accuracy: 0.972\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"fine_tuning_10000_samples.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "rmcguinn_2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}